{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. List any five functions of the pandas library with execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Absolutely, bro! Here are five common functions from the Pandas library along with their brief explanations and example executions:\n",
    "\n",
    "1. **`read_csv`**: This function is used to read data from a CSV file and create a DataFrame.\n",
    "2. **`head`**: This function displays the first few rows of a DataFrame, giving you a quick overview of the data.\n",
    "3. **`describe`**: This function provides summary statistics of the DataFrame's numeric columns, like mean, min, max, etc.\n",
    "4. **`groupby`**: This function is used to group data based on one or more columns and perform aggregate operations.\n",
    "5. **`plot`**: This function allows you to create various types of plots directly from a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Category'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Om Bade\\Desktop\\DATA_SCIENCE\\00Assignments\\20_pandas_advance_24feb.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Desktop/DATA_SCIENCE/00Assignments/20_pandas_advance_24feb.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mdescribe())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Desktop/DATA_SCIENCE/00Assignments/20_pandas_advance_24feb.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Grouping by 'Category' column and calculating mean of 'Value' column\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Desktop/DATA_SCIENCE/00Assignments/20_pandas_advance_24feb.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m grouped \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mCategory\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m'\u001b[39m\u001b[39mSurvived\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmean()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Desktop/DATA_SCIENCE/00Assignments/20_pandas_advance_24feb.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(grouped)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Desktop/DATA_SCIENCE/00Assignments/20_pandas_advance_24feb.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Om Bade\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:7631\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   7627\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   7629\u001b[0m \u001b[39m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[0;32m   7630\u001b[0m \u001b[39m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[1;32m-> 7631\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   7632\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   7633\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[0;32m   7634\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   7635\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   7636\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[0;32m   7637\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   7638\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[0;32m   7639\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   7640\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m   7641\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[0;32m   7642\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Om Bade\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:889\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    887\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> 889\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[0;32m    890\u001b[0m         obj,\n\u001b[0;32m    891\u001b[0m         keys,\n\u001b[0;32m    892\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    893\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    894\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    895\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m    896\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[0;32m    897\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[0;32m    898\u001b[0m     )\n\u001b[0;32m    900\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[0;32m    901\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32mc:\\Users\\Om Bade\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:862\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    860\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    863\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    865\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Category'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Reading a CSV file into a DataFrame\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\") \n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Display summary statistics of numeric columns\n",
    "print(df.describe())\n",
    "\n",
    "# Grouping by 'Category' column and calculating mean of 'Value' column\n",
    "grouped = df.groupby('Category')['Survived'].mean()\n",
    "print(grouped)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting a bar chart of 'Value' column\n",
    "df.plot(kind='bar', x='Category', y='Value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Given a Pandas DataFrame df with columns 'A', 'B', and 'C', write a Python function to re-index the DataFrame with a new index that starts from 1 and increments by 2 for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C\n",
       "2  3.0    5  6.0\n",
       "4  NaN  NaN  NaN\n",
       "6  NaN  NaN  NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mydata ={\n",
    "    'A' :[1,2,3],\n",
    "    'B': [4.0,'a',5],\n",
    "    'C' :[3,5,6]\n",
    "}\n",
    "df = pd.DataFrame(mydata)\n",
    "df.reindex([2,4,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. You have a Pandas DataFrame df with a column named 'Values'. Write a Python function that iterates over the DataFrame and calculates the sum of the first three values in the 'Values' column. The function should print the sum to the console.\n",
    "\n",
    "For example, if the 'Values' column of df contains the values [10, 20, 30, 40, 50], your function should \n",
    "calculate and print the sum of the first three values, which is 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     10\n",
       "4     20\n",
       "6     30\n",
       "8     40\n",
       "10    50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mydata = {\n",
    " 'val' : [10, 20, 30, 40, 50]}\n",
    "df=pd.DataFrame( mydata)\n",
    "# df2 = df['val'].apply()\n",
    "\n",
    "s4 = pd.Series([3,4,5,6,6] , index=[2,4,5,6,1])\n",
    "s1 = pd.Series([10,20,30,40,50], index=[1,4,6,8,10])\n",
    "s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Given a Pandas DataFrame df with a column 'Text', write a Python function to create a new column 'Word_Count' that contains the number of words in each row of the 'Text' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_word_count_column(df):\n",
    "    df['Word_Count'] = df['Text'].apply(lambda x: len(x.split()))\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "data = {'Text': [\"Hello there\", \"How's it going?\", \"Just chilling and enjoying\"]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Adding the 'Word_Count' column\n",
    "df_with_word_count = add_word_count_column(df)\n",
    "print(df_with_word_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. How are DataFrame.size() and DataFrame.shape() different?\n",
    "Ans -> . Both `DataFrame.size` and `DataFrame.shape` are attributes in Pandas DataFrames, \n",
    "1. **DataFrame.size:** This attribute gives you the total number of elements in the DataFrame. It's calculated as the product of the number of rows and the number of columns. So, if you have a DataFrame with 5 rows and 3 columns, the `DataFrame.size` would be 15.\n",
    "\n",
    "2. **DataFrame.shape:** This attribute returns a tuple representing the dimensions of the DataFrame. It gives you two values: the number of rows and the number of columns. For the same DataFrame as above, `DataFrame.shape` would be `(5, 3)`.\n",
    "\n",
    "In essence, `DataFrame.size` gives you the total count of elements (cells) in the DataFrame, while `DataFrame.shape` provides the dimensions (rows and columns) of the DataFrame. Keep in mind these differences when working with Pandas DataFrames, bro!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame.size: 9\n",
      "DataFrame.shape: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a sample DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [25, 30, 28],\n",
    "        'City': ['New York', 'Los Angeles', 'Chicago']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Using DataFrame.size\n",
    "size = df.size  # This will be 3 (rows) * 3 (columns) = 9\n",
    "print(\"DataFrame.size:\", size)\n",
    "\n",
    "# Using DataFrame.shape\n",
    "shape = df.shape  # This will be a tuple (3, 3) representing 3 rows and 3 columns\n",
    "print(\"DataFrame.shape:\", shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Which function of pandas do we use to read an excel file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Om Bade\\Desktop\\DATA_SCIENCE\\00Assignments\\20_pandas_advance_24feb.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Desktop/DATA_SCIENCE/00Assignments/20_pandas_advance_24feb.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Desktop/DATA_SCIENCE/00Assignments/20_pandas_advance_24feb.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Replace 'file_path.xlsx' with the actual path to your Excel file\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Desktop/DATA_SCIENCE/00Assignments/20_pandas_advance_24feb.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_excel(\u001b[39m'\u001b[39;49m\u001b[39msya.xlsx\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Desktop/DATA_SCIENCE/00Assignments/20_pandas_advance_24feb.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Now 'df' contains the data from the Excel file in a DataFrame\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Desktop/DATA_SCIENCE/00Assignments/20_pandas_advance_24feb.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(df)\n",
      "File \u001b[1;32mc:\\Users\\Om Bade\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Om Bade\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\excel\\_base.py:364\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    363\u001b[0m     should_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 364\u001b[0m     io \u001b[39m=\u001b[39m ExcelFile(io, storage_options\u001b[39m=\u001b[39;49mstorage_options, engine\u001b[39m=\u001b[39;49mengine)\n\u001b[0;32m    365\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39mand\u001b[39;00m engine \u001b[39m!=\u001b[39m io\u001b[39m.\u001b[39mengine:\n\u001b[0;32m    366\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    367\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    368\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    369\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Om Bade\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1233\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1230\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine \u001b[39m=\u001b[39m engine\n\u001b[0;32m   1231\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage_options \u001b[39m=\u001b[39m storage_options\n\u001b[1;32m-> 1233\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engines[engine](\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_io, storage_options\u001b[39m=\u001b[39;49mstorage_options)\n",
      "File \u001b[1;32mc:\\Users\\Om Bade\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:521\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    507\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    508\u001b[0m     filepath_or_buffer: FilePathOrBuffer,\n\u001b[0;32m    509\u001b[0m     storage_options: StorageOptions \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    510\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    511\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \u001b[39m    Reader using openpyxl engine.\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[39m        passed to fsspec for appropriate URLs (see ``_get_filepath_or_buffer``)\u001b[39;00m\n\u001b[0;32m    520\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 521\u001b[0m     import_optional_dependency(\u001b[39m\"\u001b[39;49m\u001b[39mopenpyxl\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    522\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(filepath_or_buffer, storage_options\u001b[39m=\u001b[39mstorage_options)\n",
      "File \u001b[1;32mc:\\Users\\Om Bade\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\compat\\_optional.py:118\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 118\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    119\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'file_path.xlsx' with the actual path to your Excel file\n",
    "df = pd.read_excel('sya.xlsx')\n",
    "\n",
    "# Now 'df' contains the data from the Excel file in a DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. You have a Pandas DataFrame df that contains a column named 'Email' that contains email addresses in the format 'username@domain.com'. Write a Python function that creates a new column 'Username' in df that contains only the username part of each email address.\n",
    "\n",
    "The username is the part of the email address that appears before the '@' symbol. For example, if the \n",
    "email address is 'john.doe@example.com', the 'Username' column should contain 'john.doe'. Your \n",
    "function should extract the username from each email address and store it in the new 'Username' \n",
    "column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>john.doe@example.com</td>\n",
       "      <td>john.doe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jane.smith@example.com</td>\n",
       "      <td>jane.smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bob.jones@example.com</td>\n",
       "      <td>bob.jones</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Email    username\n",
       "0    john.doe@example.com    john.doe\n",
       "1  jane.smith@example.com  jane.smith\n",
       "2   bob.jones@example.com   bob.jones"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def strsplit(email):\n",
    "    user = email.split('@')[0]\n",
    "    return user\n",
    "\n",
    "data = {'Email': ['john.doe@example.com', 'jane.smith@example.com', 'bob.jones@example.com']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['username'] = df['Email'].apply(strsplit)\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def euro_inr(x):\n",
    "#     return x*80\n",
    "\n",
    "# df['Fare_INR'] = df['Fare'].apply(euro_inr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. You have a Pandas DataFrame df with columns 'A', 'B', and 'C'. Write a Python function that selects all rows where the value in column 'A' is greater than 5 and the value in column 'B' is less than 10. The function should return a new DataFrame that contains only the selected rows.\n",
    "\n",
    "For example, if df contains the following values:\n",
    "\n",
    "   A   B   C\n",
    "\n",
    "0  3   5   1\n",
    "\n",
    "1  8   2   7\n",
    "\n",
    "2  6   9   4\n",
    "\n",
    "3  2   3   5\n",
    "\n",
    "4  9   1   2\n",
    "\n",
    "Your function should select the following rows:   A   B   C\n",
    "\n",
    "1  8   2   7\n",
    "\n",
    "4  9   1   2\n",
    "\n",
    "The function should return a new DataFrame that contains only the selected rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "1  8  2  7\n",
      "4  9  1  2\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# mydata = {\n",
    "#     'A' : [3,8,6,2,9],\n",
    "#     'B' : [5,2,9,3,1],\n",
    "#     'C' :[1,7,4,5,2]\n",
    "# }\n",
    "# df1 = pd.DataFrame(mydata)\n",
    "# df1\n",
    "# df1[['A','B','C']][1:5:1]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def select_rows(df):\n",
    "    selected_rows = df[(df['A'] > 5) & (df['B'] < 10)]\n",
    "    return selected_rows\n",
    "\n",
    "# Example usage\n",
    "data = {'A': [3, 8, 6, 2, 9],\n",
    "        'B': [5, 2, 9, 3, 1],\n",
    "        'C': [1, 7, 4, 5, 2]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Selecting rows\n",
    "selected_df = select_rows(df)\n",
    "print(selected_df[0:3:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. Given a Pandas DataFrame df with a column 'Sales' and a column 'Date', write a Python function to create a new column 'MovingAverage' that contains the moving average of the sales for the past 7 days for each row in the DataFrame. The moving average should be calculated using a window of size 7 and should include the current day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_moving_average(df):\n",
    "    window_size = 7\n",
    "    \n",
    "    # Convert the 'Date' column to datetime if it's not already\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # Sort DataFrame by date\n",
    "    df.sort_values(by='Date', inplace=True)\n",
    "    \n",
    "    # Calculate the moving average using rolling and mean functions\n",
    "    df['MovingAverage'] = df['Sales'].rolling(window=window_size, min_periods=1).mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "data = {'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', '2023-01-06', '2023-01-07'],\n",
    "        'Sales': [10, 15, 20, 25, 30, 35, 40]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate moving average\n",
    "df_with_ma = calculate_moving_average(df)\n",
    "print(df_with_ma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q11. You have a Pandas DataFrame df with a column 'Date'. Write a Python function that creates a new column 'Weekday' in the DataFrame. The 'Weekday' column should contain the weekday name (e.g. Monday, Tuesday) corresponding to each date in the 'Date' column.\n",
    "\n",
    "For example, if df contains the following values:\n",
    "\n",
    "         Date\n",
    "\n",
    "0  2023-01-01\n",
    "\n",
    "1  2023-01-02\n",
    "\n",
    "2  2023-01-03\n",
    "\n",
    "3  2023-01-04\n",
    "\n",
    "4  2023-01-05\n",
    "\n",
    "Your function should create the following DataFrame:\n",
    "\n",
    "\n",
    "         Date    Weekday\n",
    "\n",
    "0  2023-01-01    Sunday\n",
    "\n",
    "1  2023-01-02     Monday\n",
    "\n",
    "2  2023-01-03    Tuesday\n",
    "\n",
    "3  2023-01-04    Wednesday\n",
    "\n",
    "4  2023-01-05    Thursday\n",
    "\n",
    "The function should return the modified DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_weekday_column(df):\n",
    "    df['Date'] = pd.to_datetime(df['Date'])  # Convert 'Date' column to datetime if not already\n",
    "    df['Weekday'] = df['Date'].dt.strftime('%A')  # Extract weekday name and add to new column\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "data = {'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Add 'Weekday' column\n",
    "df_with_weekday = add_weekday_column(df)\n",
    "print(df_with_weekday)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q12. Given a Pandas DataFrame df with a column 'Date' that contains timestamps, write a Python function to select all rows where the date is between '2023-01-01' and '2023-01-31'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date\n",
      "0 2023-01-15\n",
      "1 2023-01-25\n",
      "3 2023-01-10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def select_rows_between_dates(df):\n",
    "    start_date = '2023-01-01'\n",
    "    end_date = '2023-01-31'\n",
    "    \n",
    "    # Convert the 'Date' column to datetime if it's not already\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    selected_rows = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "    return selected_rows\n",
    "\n",
    "# Example usage\n",
    "data = {'Date': ['2023-01-15', '2023-01-25', '2023-02-05', '2023-01-10']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Selecting rows between dates\n",
    "selected_df = select_rows_between_dates(df)\n",
    "print(selected_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q13. To use the basic functions of pandas, what is the first and foremost necessary library that needs to be imported?\n",
    "Ans -> To use the basic functions of pandas, the first and foremost library you need to import is `pandas` itself. You can import it using the `import` statement in your Python code:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "By convention, `pandas` is commonly aliased as `pd` to make the code shorter and easier to read. Once you've imported `pandas`, you'll have access to all its functions and classes for data manipulation and analysis using DataFrames and Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
