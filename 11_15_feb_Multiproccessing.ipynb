{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. What is multiprocessing in python? Why is it useful?Â \n",
    "Multiprocessing in Python refers to the ability of a program to create and execute multiple processes concurrently. A process is an independent unit of execution that runs in its memory space, separate from other processes. Each process can have its own Python interpreter, allowing for true parallelism, unlike multithreading, which is limited by the Global Interpreter Lock (GIL).\n",
    "\n",
    "In Python, the \"multiprocessing\" module provides a high-level interface for creating and managing multiple processes. It allows you to take advantage of multiple CPU cores and distribute workload across them, leading to improved performance and efficient utilization of resources.\n",
    "\n",
    "The \"multiprocessing\" module is useful for several reasons:\n",
    "\n",
    "1. **True Parallelism**: Unlike multithreading, multiprocessing allows for true parallel execution of tasks, as each process runs independently in its memory space. This is particularly beneficial for CPU-bound tasks, where performance gains can be significant.\n",
    "\n",
    "2. **Utilizing Multiple Cores**: With multiprocessing, you can leverage the power of modern multi-core processors. By running processes on different cores, you can divide complex computations into smaller chunks and process them simultaneously, reducing overall processing time.\n",
    "\n",
    "3. **Isolation and Stability**: Each process operates independently, which means that if one process crashes or encounters an error, it does not affect other processes. This isolation enhances the stability and reliability of the overall program.\n",
    "\n",
    "4. **Resource Sharing**: Although processes run in separate memory spaces, the \"multiprocessing\" module provides mechanisms for sharing data between processes, such as pipes, queues, and shared memory. This allows for efficient communication and coordination between different processes.\n",
    "\n",
    "5. **Avoiding GIL Limitations**: Python's Global Interpreter Lock (GIL) restricts the execution of Python threads concurrently, limiting the benefits of multithreading for CPU-bound tasks. Multiprocessing sidesteps this limitation by using separate Python interpreters for each process.\n",
    "\n",
    "6. **Scalability**: Multiprocessing is scalable and can handle tasks of varying complexities. You can adjust the number of processes based on the available CPU cores and the nature of the workload.\n",
    "\n",
    "Overall, multiprocessing is a powerful feature in Python that enables developers to harness the full potential of modern hardware, distribute tasks effectively, and achieve true parallelism, making it a valuable tool for performance-critical and CPU-intensive applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. What are the differences between multiprocessing and multithreading?\n",
    "Multiprocessing and multithreading are both techniques used to achieve concurrent execution in Python, but they have significant differences in how they work and what they offer. Let's explore the main differences between multiprocessing and multithreading:\n",
    "\n",
    "1. **Execution Model:**\n",
    "   - Multiprocessing: In multiprocessing, each process runs independently in its memory space, with its own Python interpreter. Processes do not share memory by default, which ensures isolation between them.\n",
    "   - Multithreading: In multithreading, multiple threads run within the same process and share the same memory space. Threads have access to shared variables and data structures, which can lead to synchronization and data sharing issues.\n",
    "\n",
    "2. **Parallelism:**\n",
    "   - Multiprocessing: Multiprocessing provides true parallelism since each process can be executed on a separate CPU core. This allows for maximum utilization of multiple CPU cores for CPU-bound tasks.\n",
    "   - Multithreading: Multithreading does not provide true parallelism due to the Global Interpreter Lock (GIL) in CPython, which restricts the execution of Python bytecode to a single thread at a time. This limitation makes multithreading more suitable for I/O-bound tasks rather than CPU-bound tasks.\n",
    "\n",
    "3. **Resource Sharing and Synchronization:**\n",
    "   - Multiprocessing: Processes do not share memory by default, but the \"multiprocessing\" module provides mechanisms like pipes, queues, and shared memory for interprocess communication and coordination.\n",
    "   - Multithreading: Threads share the same memory space, allowing them to easily share data and variables. However, this shared access requires proper synchronization mechanisms (e.g., locks, semaphores) to avoid race conditions and ensure thread safety.\n",
    "\n",
    "4. **Isolation and Stability:**\n",
    "   - Multiprocessing: Since processes run independently, if one process crashes, it does not affect others. This isolation enhances the stability and reliability of the program.\n",
    "   - Multithreading: Threads within the same process are tightly connected, so if one thread encounters an error (e.g., segmentation fault), it can crash the entire process, affecting all other threads.\n",
    "\n",
    "5. **Complexity:**\n",
    "   - Multiprocessing: Implementing multiprocessing can be more complex due to the separate memory space for processes and the need for interprocess communication.\n",
    "   - Multithreading: Multithreading can be simpler to implement since threads share memory and do not require explicit communication mechanisms. However, handling thread synchronization and avoiding race conditions can add complexity.\n",
    "\n",
    "6. **Use Cases:**\n",
    "   - Multiprocessing: Multiprocessing is well-suited for CPU-bound tasks that can benefit from true parallel execution, especially on systems with multiple CPU cores.\n",
    "   - Multithreading: Multithreading is beneficial for I/O-bound tasks that involve waiting for I/O operations (e.g., reading/writing files, making network requests) since threads can continue executing other tasks during these waits.\n",
    "\n",
    "In summary, multiprocessing and multithreading serve different purposes and offer distinct advantages based on the nature of the tasks and the available hardware resources. Multiprocessing is suitable for CPU-bound tasks and parallelism, while multithreading is more suitable for I/O-bound tasks and responsiveness.ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Write a python code to create a process using the multiprocessing module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from the main process!\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def print_hello():\n",
    "    print(\"Hello from the child process!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a new process\n",
    "    process = multiprocessing.Process(target=print_hello)\n",
    "\n",
    "    # Start the process\n",
    "    process.start()\n",
    "\n",
    "    # Wait for the process to complete\n",
    "    process.join()\n",
    "\n",
    "    # Print from the main process\n",
    "    print(\"Hello from the main process!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. What is a multiprocessing pool in python? Why is it used?\n",
    "A multiprocessing pool in Python is a convenient feature provided by the \"multiprocessing\" module to manage a pool of worker processes. It allows you to parallelize the execution of a function across multiple input values or tasks. The pool distributes the tasks among the available processes, making it easy to harness the power of multiple CPU cores for concurrent execution.\n",
    "\n",
    "The main components of a multiprocessing pool are:\n",
    "\n",
    "1. **Worker Processes**: The pool creates a specified number of worker processes, usually equal to the number of CPU cores available on the system. Each worker process runs in its memory space and can execute tasks independently.\n",
    "\n",
    "2. **Task Distribution**: When you submit tasks to the pool, it divides them among the worker processes, distributing the workload across the pool.\n",
    "\n",
    "3. **Result Collection**: As the worker processes complete their tasks, the pool collects and stores the results for each task, making it easy to retrieve the results once all tasks are complete.\n",
    "\n",
    "The `multiprocessing.Pool` class provides the pool functionality. It can be used to parallelize computations, perform data processing tasks in parallel, or distribute I/O-bound tasks efficiently.\n",
    "\n",
    "The main benefits of using a multiprocessing pool are:\n",
    "\n",
    "1. **Efficient Utilization of CPU Cores**: A pool allows you to utilize multiple CPU cores effectively, speeding up the execution of CPU-bound tasks.\n",
    "\n",
    "2. **Simplified Task Parallelism**: The pool abstracts away the complexity of managing individual processes and distributing tasks. You can easily submit tasks to the pool and let it handle the parallel execution.\n",
    "\n",
    "3. **Result Aggregation**: The pool automatically collects and stores the results of each task, making it easy to retrieve the output once all tasks are complete.\n",
    "\n",
    "4. **Improved Responsiveness**: Using a pool can lead to improved responsiveness for tasks involving I/O operations, as other processes can continue running while waiting for I/O to complete.\n",
    "\n",
    "Here's a simple example to demonstrate the use of a multiprocessing pool:\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inputs = [1, 2, 3, 4, 5]\n",
    "\n",
    "    # Create a multiprocessing pool with 2 worker processes\n",
    "    with multiprocessing.Pool(processes=2) as pool:\n",
    "        results = pool.map(square, inputs)\n",
    "\n",
    "    print(\"Squared results:\", results)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Squared results: [1, 4, 9, 16, 25]\n",
    "```\n",
    "\n",
    "In this example, we define a function `square(x)` to calculate the square of a number. We create a list of input values (`inputs`) and use a multiprocessing pool with two worker processes (`processes=2`) to calculate the squares of all elements in the `inputs` list. The `pool.map()` method is used to distribute the tasks (applying the `square()` function to each input) among the worker processes. The results are collected in the `results` list and printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. How can we create a pool of worker processes in python using the multiprocessing module?\n",
    "To create a pool of worker processes in Python using the `multiprocessing` module, you can use the `multiprocessing.Pool` class. The `Pool` class provides a simple and convenient way to manage a pool of worker processes and distribute tasks among them. Here's how you can create a pool of worker processes:\n",
    "\n",
    "1. Import the `multiprocessing` module.\n",
    "\n",
    "2. Define the function that each worker process will execute. This function will be called with different input values (tasks) that you want to process in parallel.\n",
    "\n",
    "3. Create a list of input values or tasks that you want to process in parallel.\n",
    "\n",
    "4. Create a `Pool` object by using the `multiprocessing.Pool()` constructor. The constructor takes an optional argument `processes`, which specifies the number of worker processes to create. If not provided, it will use the number of CPU cores available on your system.\n",
    "\n",
    "5. Use the `Pool.map()` method to distribute the tasks among the worker processes. The `map()` method takes the function to be executed (the one defined in step 2) and the list of input values (tasks). It will apply the function to each input value and return the results.\n",
    "\n",
    "6. Remember to close the pool using the `Pool.close()` method and wait for all the worker processes to complete using the `Pool.join()` method.\n",
    "\n",
    "Here's an example to demonstrate the process:\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "# Function to be executed by worker processes\n",
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # List of input values\n",
    "    inputs = [1, 2, 3, 4, 5]\n",
    "\n",
    "    # Create a multiprocessing pool with 2 worker processes\n",
    "    with multiprocessing.Pool(processes=2) as pool:\n",
    "        # Distribute the tasks among the worker processes and get the results\n",
    "        results = pool.map(square, inputs)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Squared results:\", results)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Squared results: [1, 4, 9, 16, 25]\n",
    "```\n",
    "\n",
    "In this example, we define a function `square(x)` to calculate the square of a number. We create a list of input values (`inputs`) and use a multiprocessing pool with two worker processes (`processes=2`) to calculate the squares of all elements in the `inputs` list. The `pool.map()` method distributes the tasks (applying the `square()` function to each input) among the worker processes, and the results are collected in the `results` list and printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Write a python program to create 4 processes, each process should print a different number using the multiprocessing module in python.\n",
    "Sure, here's a Python program that creates 4 processes, and each process prints a different number:\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def print_number(number):\n",
    "    print(f\"Process {number}: {number}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a list of numbers for each process\n",
    "    numbers = [1, 2, 3, 4]\n",
    "\n",
    "    # Create a multiprocessing pool with 4 worker processes\n",
    "    with multiprocessing.Pool(processes=4) as pool:\n",
    "        # Distribute the tasks among the worker processes\n",
    "        pool.map(print_number, numbers)\n",
    "```\n",
    "\n",
    "Output (example output; order may vary due to multiprocessing):\n",
    "```\n",
    "Process 1: 1\n",
    "Process 2: 2\n",
    "Process 4: 4\n",
    "Process 3: 3\n",
    "```\n",
    "\n",
    "In this program, we define the function `print_number(number)` to print the given number along with the process number. We create a list of numbers (`numbers`) that we want to print using the processes.\n",
    "\n",
    "Then, we use the `multiprocessing.Pool` class with 4 worker processes (`processes=4`). The `pool.map()` method distributes the tasks (printing each number) among the worker processes. Each process prints its respective number along with its process number, resulting in four different numbers printed by four different processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Colors: [2 1 0 2 1 0]\n",
      "Color Labels: ['blue' 'green' 'red']\n",
      "Encoded Sizes: [2 1 0 1 2 0]\n",
      "Size Labels: ['large' 'medium' 'small']\n",
      "Encoded Materials: [2 0 1 0 1 2]\n",
      "Material Labels: ['metal' 'plastic' 'wood']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample dataset with categorical variables\n",
    "colors = ['red', 'green', 'blue', 'red', 'green', 'blue']\n",
    "sizes = ['small', 'medium', 'large', 'medium', 'small', 'large']\n",
    "materials = ['wood', 'metal', 'plastic', 'metal', 'plastic', 'wood']\n",
    "\n",
    "# Create a LabelEncoder object for each categorical variable\n",
    "color_encoder = LabelEncoder()\n",
    "size_encoder = LabelEncoder()\n",
    "material_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the categorical variables to obtain the encoded labels\n",
    "encoded_colors = color_encoder.fit_transform(colors)\n",
    "encoded_sizes = size_encoder.fit_transform(sizes)\n",
    "encoded_materials = material_encoder.fit_transform(materials)\n",
    "\n",
    "# Print the encoded labels and the mapping of categories to labels\n",
    "print(\"Encoded Colors:\", encoded_colors)\n",
    "print(\"Color Labels:\", color_encoder.classes_)\n",
    "print(\"Encoded Sizes:\", encoded_sizes)\n",
    "print(\"Size Labels:\", size_encoder.classes_)\n",
    "print(\"Encoded Materials:\", encoded_materials)\n",
    "print(\"Material Labels:\", material_encoder.classes_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
